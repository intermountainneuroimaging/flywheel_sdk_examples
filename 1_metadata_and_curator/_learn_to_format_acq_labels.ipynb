{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Metadata in Flywheel\n",
    "\n",
    "Welcome! This is an introductory worksheet to explore how we can use the flywheel sdk to read and update metadata (and data) in flywheel!\n",
    "\n",
    "**Date modified:** 02/16/2025<br>\n",
    "**Authors:** Amy Hegarty, Intermountain Neuroimaging Consortium\n",
    "\n",
    "**Sections:**\n",
    "1. IMPORT STATMENTS\n",
    "2. FLYWHEEL LOGIN\n",
    "3. ACQUISITION RENAMING\n",
    "4. DELETE UNWANTED FILES\n",
    "5. UPDATE INTENDEDFOR SETS\n",
    "\n",
    "\n",
    "**NOTE**: Take special note, studies not collected using teh `reproin` naming convention should apply acquisition renaming (Workbook __Section 3__) to all data before running bids-* workflows\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting...\n",
    "1. Be sure you have configured your conda environment to view ics managed conda environments and packages. If you haven't get started [here](https://inc-documentation.readthedocs.io/en/latest/pl_and_blanca_basics.html#setting-up-conda-environments).\n",
    "\n",
    "2. Be sure to select the `incenv` kernel from the list of available kernels. If you don't see the `incenv` kernel, contact Amy Hegarty <Amy.Hegarty@colorado.edu> or follow the instructions [here](https://inc-documentation.readthedocs.io/en/latest/pl_and_blanca_basics.html#setting-up-conda-environments) to setup a new kernel in a shared conda environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __IMPORT STATEMENTS__\n",
    "Here we will load all packages used in the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Third party packages come second\n",
    "import flywheel\n",
    "from flywheel import ApiException\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __FLYWHEEL LOGIN__\n",
    "Be sure you have first logged into flywheel using the command line interface. Once you have stored your API key, you will not need to log in subsequent times. Follow instructions [here](https://inc-documentation.readthedocs.io/en/latest/cli_basics.html#cli-from-blanca-compute-node). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = flywheel.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __ACQUISITON RENAMING__\n",
    "There are many cases where it may be useful to programatically update acquisition names within a project. This is most often used when the original data was not collected using `reproin` naming convention. Example code here shows how a user can store a map `acquisition_label_remapping.csv` in Flywheel project, then apply the remapping to a given session at a click of a button. Important to note, if acquisitions have duplicate `seriesDescription` labels the second, and third, and forth, so on instances of the acqusition will be appended with a suffix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(obj):\n",
    "    return fw.get(obj.id)\n",
    "\n",
    "def acquisitions_ordered_by_number(session):\n",
    "    \"return a list acqusitions in order by series number...\"\n",
    "    \n",
    "    ordered_list = {'SeriesNumber':[],'SeriesDescription':[],'acquisition':[], 'acq_id':[]}\n",
    "    for acq in get(session).acquisitions():\n",
    "        file = next(f for f in get(acq).files if f['type'] == 'dicom')\n",
    "        if file:\n",
    "            try:\n",
    "                file.info[\"SeriesDescription\"]\n",
    "                ordered_list['SeriesDescription'] += [file.info[\"SeriesDescription\"]]\n",
    "                ordered_list['SeriesNumber'] += [file.info[\"SeriesNumber\"]]\n",
    "                ordered_list['acquisition'] += [acq.label]\n",
    "                ordered_list['acq_id'] += [acq.id]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict(ordered_list)\n",
    "    return df.sort_values('SeriesNumber',ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: apply acquisition renaming to single session (add suffix for duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_acqisitions = {\n",
    "# 'localizer_32ch': 'localizer_32ch_ignore-BIDS',\n",
    "#  'localizer_32ch_uncombined': 'localizer_32ch_uncombined_ignore-BIDS',\n",
    "#  'localizer_32ch_uncombined_1': 'localizer_32ch_uncombined_ignore-BIDS',\n",
    "#  'Combined_Image': 'Combined_Image_ignore-BIDS',\n",
    "#  'GFactor': 'GFactor_ignore-BIDS',\n",
    "#  'SNRMap': 'SNRMap_ignore-BIDS',\n",
    "#  'NoiseCovariance': 'NoiseCovariance_ignore-BIDS',\n",
    "#  'ABCD_QA_fMRI': 'func-bold_task-abcdqa_run-01',\n",
    "#  'ABCD_QA_fMRI_1':'func-bold_task-abcdqa_run-02',\n",
    "#  'ABCD_QA_dMRI': 'dwi_acq-abcdqa_run-01',\n",
    "#  'FBIRN_QA_fMRI_flip77': 'func-bold_task-abcdqa_acq-flip77_run-01',\n",
    "#  'FBIRN_QA_fMRI_flip10': 'func-bold_task-abcdqa_acq-flip10_run-01',\n",
    "#  'PhoenixZIPReport': 'PhoenixZIPReport_ignore-BIDS'\n",
    "# }\n",
    "\n",
    "# !!!SESSION!!!\n",
    "qa_session = fw.lookup('<path-to-session>')\n",
    "\n",
    "# SETP 1: pull mapping labels from flywheel\n",
    "try:\n",
    "    project = fw.get_container(qa_session.parents[\"project\"])\n",
    "    \n",
    "    # assume acquisition labeling key is called \"acquisition_label_remapping.csv\"\n",
    "    sourcefile = project.get_file(\"acquisition_label_remapping.csv\")\n",
    "    \n",
    "    # read file directly to memory\n",
    "    data_str = sourcefile.read().decode('utf-8')\n",
    "    \n",
    "    # import as dictionary\n",
    "    rename_acqisitions = {row[0] : row[1] for _, row in pd.read_csv(StringIO(data_str)).iterrows()}\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"unable to load acquisition labeling from flywheel...\")\n",
    "    raise e\n",
    "\n",
    "# start by putting the acquisitions in series number order!!! -- Doesn't always start this way!\n",
    "ordered_list = acquisitions_ordered_by_number(qa_session)\n",
    "reset = False\n",
    "\n",
    "# loop through acquisitions (in order and relabelling...)\n",
    "for index, row in ordered_list.iterrows():\n",
    "    acq = fw.get(row[\"acq_id\"])\n",
    "    \n",
    "    # find new acquisition label from dictionary\n",
    "    try:    \n",
    "        new_label = rename_acqisitions[acq.label]\n",
    "    except:\n",
    "        new_label = acq.label\n",
    "    \n",
    "    # This is for troubleshooting only, resets the labels to the default from the scanner import\n",
    "    if reset:\n",
    "        new_label=row[\"SeriesDescription\"]\n",
    "    \n",
    "    # if duplicates exist (update command fails) , you will need to append with a numeric suffix.. \n",
    "    for i in range(10):\n",
    "        suffix = f\"_{i}\" if i > 0 else \"\"\n",
    "        try:\n",
    "            new_label += suffix\n",
    "            full_acq.update({'label': new_label})\n",
    "            print(f\"updating: {acq.label} ---> {new_label}\")\n",
    "            break\n",
    "        except ApiException:\n",
    "            # label already in use... increase counter and try again\n",
    "            print(\"igornoring ApiExpection\")\n",
    "        except Exception as e:\n",
    "            raise(e)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __DELETE UNWANTED FILES (E.G. DERIVATIVE LOCALIZER FILES)__\n",
    "Removing data from Flywheel should not be taken lightly! Always run in `dry_run` mode before executing. Specific situations may warrent programatically deleting files such as removing extraneous derivative files.\n",
    "\n",
    "__NEVER DELETE SOURCE DATA!!__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session  = fw.lookup('<path-to-session>')\n",
    "dry_run = True\n",
    "for acq in session.acquisitions():\n",
    "    if \"localizer\" in acq.label:\n",
    "        full_acq = fw.get(acq.id)\n",
    "        for f in full_acq.files:\n",
    "            if f.type == 'nifti':\n",
    "                print(f.name)\n",
    "                if not dry_run:\n",
    "                    fw.delete_file(f.file_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __UPDATE INTENDEDFOR SETS WHEN MULTIPLE FIELDMAPS PAIRS EXIST__\n",
    "Some occasions we may need to re-assign the fMRI / dMRI files which should be distortion corrected with a matching fieldmap pair. These are generally matched to the same geometric dimensions and as close in time as possible during data acquisition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lookup(full_session):\n",
    "    sdescrp=[]; snum=[]; acq_name=[]; acq_id=[]; bids_label=[]; task=[]; folder=[]; direction=[]\n",
    "    \n",
    "    for acq in full_session.acquisitions():\n",
    "        # intialize / resest apply flag\n",
    "        full_acq = fw.get_acquisition(acq.id)\n",
    "        \n",
    "        if \"ignore-BIDS\" not in acq.label:\n",
    "            for file in full_acq['files']:\n",
    "                if file['type'] == 'nifti':\n",
    "                    if \"SeriesDescription\" not in file.info:\n",
    "                        continue\n",
    "                    sdescrp.append(file.info[\"SeriesDescription\"])\n",
    "                    snum.append(file.info[\"SeriesNumber\"])\n",
    "                    acq_name.append(acq.label)\n",
    "                    acq_id.append(acq.id)\n",
    "                    \n",
    "                    if file.info[\"BIDS\"]:\n",
    "                        bids_label.append(\"ses-\"+full_session.label+\"/\"+file.info[\"BIDS\"][\"Folder\"]+\"/\"+file.info[\"BIDS\"][\"Filename\"])\n",
    "                    else:\n",
    "                        bids_label.append(None)\n",
    "                    \n",
    "                    if \"Task\" in file.info[\"BIDS\"]:\n",
    "                        task.append(file.info[\"BIDS\"][\"Task\"])\n",
    "                    else:\n",
    "                        task.append(None)\n",
    "                        \n",
    "                    if \"Dir\" in file.info[\"BIDS\"]:\n",
    "                        direction.append(file.info[\"BIDS\"][\"Dir\"])\n",
    "                    else:\n",
    "                        direction.append(None)\n",
    "                        \n",
    "                    if \"Folder\" in file.info[\"BIDS\"]:\n",
    "                        folder.append(file.info[\"BIDS\"][\"Folder\"])\n",
    "                    else:\n",
    "                        folder.append(None)\n",
    "                        \n",
    "                    break\n",
    "                \n",
    "    df = pd.DataFrame({\"SeriesNumber\": snum, \n",
    "                       \"SeriesName\": sdescrp, \n",
    "                       \"Acquisition\":acq_name, \n",
    "                       \"ID\": acq_id, \n",
    "                       \"BIDS\": bids_label,\n",
    "                       \"Modality\": folder,\n",
    "                       \"Task\": task,\n",
    "                       \"Direction\": direction})\n",
    "    df = df.sort_values(\"SeriesNumber\", ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def list_to_dict(rlist):\n",
    "    rlist = [x.strip(' ') for x in rlist]\n",
    "    return dict(map(lambda s : s.split(': '), rlist))\n",
    "\n",
    "\n",
    "# automatically determine which scans go with which fieldmap (using scan order and filters if given...)\n",
    "def assign_intendedfors(acq_name, lookup_table, mod_filter=None, task_filter=None, force_acq_order=True):\n",
    "    \n",
    "    df = lookup_table\n",
    "    \n",
    "    # find direction order to ignore: reverse current direction order (used for reverse phase encoding)\n",
    "    ignore_dir = df.loc[df['Acquisition'] == acq_name, 'Direction'].iat[0][::-1]  \n",
    "    \n",
    "    # limit lookup table to sequences after the fieldmap of interest\n",
    "    df = df[(df['Acquisition'] == acq_name).idxmax():]\n",
    "    \n",
    "    # ignore fieldmaps of opposing directions.\n",
    "    index_ignore = df[(df['Direction']==ignore_dir) & (df['Modality']==\"fmap\")].index\n",
    "    if not index_ignore.empty:\n",
    "        df = df.drop(index_ignore)\n",
    "     \n",
    "    # finally...generate list of all acqs after current fieldmap, before next fieldmap is collected\n",
    "    if force_acq_order:\n",
    "        if \"fmap\" in df['Modality'][1:].values:\n",
    "            df = df.loc[: df[(df['Modality'] == 'fmap')].index[1], :]\n",
    "        \n",
    "    # if task filter is given reduce lookup table to only desired tasks\n",
    "    if task_filter:\n",
    "        df = df[df['Task'].isin(task_filter)]\n",
    "        \n",
    "    # if modality filter is given reduce lookup table to only desired tasks\n",
    "    if mod_filter:\n",
    "        df = df[df['Modality'].isin(mod_filter)]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: update intendedFors for single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = True\n",
    "\n",
    "ses = (fw.get_session(\"<session-id>\"))\n",
    "\n",
    "tab = build_lookup(actual_session)\n",
    "\n",
    "# generate new intendedfor sets:\n",
    "for index, row in tab[tab['Modality'] == \"fmap\"].iterrows():\n",
    "\n",
    "    df = assign_intendedfors(tab['Acquisition'].iat[index],tab,mod_filter=[\"func\",\"dwi\"])\n",
    "\n",
    "    pull_acq = fw.get_acquisition(tab['ID'].iat[index])\n",
    "    print(tab['Acquisition'].iat[index])\n",
    "    \n",
    "    for ffile in pull_acq.files:\n",
    "        if ffile.type in ['nifti']:\n",
    "            #Get info object\n",
    "            ffile_info=ffile.info\n",
    "            old_intendedfor = ffile_info['IntendedFor']\n",
    "            ffile_info['IntendedFor']=df[\"BIDS\"].values.tolist()\n",
    "\n",
    "            print(old_intendedfor)\n",
    "            print('----------------->>>>>>')\n",
    "            print(df[\"BIDS\"].values.tolist())\n",
    "            print('=======================')\n",
    "\n",
    "\n",
    "    if not dry_run:\n",
    "        ffile.replace_info(ffile_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incenv",
   "language": "python",
   "name": "incenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
